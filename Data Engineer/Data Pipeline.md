---
tags:
  - data_engineer
---
# ğŸ‡«ğŸ‡·
Le [[Data Pipeline]] sert Ã  automatiser le flux de donnÃ©es d'un point A Ã  un point B. Il garantit la circulation efficace des donnÃ©es au sein de l'organisation, en automatisant les processus tels que l'extraction, la transformation et le chargement (ETL). Un bon pipeline rÃ©duit l'intervention humaine, les erreurs et accÃ©lÃ¨re la circulation des donnÃ©es.
# Exemple de pipeline chez Spotify

![[data_pipeline.png]]
1. Nous avons des sources Ã  partir desquelles nous extrayons des donnÃ©es, par exemple les actions des utilisateurs, lâ€™historique des Ã©coutes sur les tÃ©lÃ©phones sur lâ€™application mobile ou lâ€™application web. Il y a aussi lâ€™application interne, pour le management de la masse salariale et les bÃ©nÃ©fices. Ces donnÃ©es sont ingÃ©rÃ©es dans le process. (**3 pipelines**)
2. Ces sources sont rÃ©cupÃ©rÃ©s Ã  leurs sources jusquâ€™au [[Data lake]].
3. Ces donnÃ©es sont dÃ©placÃ©es dans des bases de donnÃ©es (**6 pipelines**)
    1. **Artists** (nom, nombre de followers, actes associÃ©s)
    2. **Albums** (label, producteur, annÃ©e de publication)
    3. **Tracks** (nom, longueur, artistes, nombre dâ€™Ã©coutes)
    4. **Playlists** (nom, liste des sons, date de crÃ©ation)
    5. **Customers** (username, date de crÃ©ation de compte, niveau dâ€™abonnement)
    6. **Employees**(nom, salaire, responsable)
4. Des donnÃ©es peuvent encore Ãªtre [[Data processing]] (**5 pipelines**)
    1. Certains albums peuvent Ãªtre directement extraits et stockÃ©, les covers dâ€™albums ont tous le mÃªme format, donc on peut directement les stocker sans les crops.
    2. **Employees** peut Ãªtre split en diffÃ©rentes tables, par dÃ©partement, sales, engineering, support, etc.
    3. **Tracks** doit Ãªtre process, pour voir si les tracks sont lisibles, lâ€™artiste correspondant est dans la base de donnÃ©es, le fichier Ã  une taille correcte, un format correcte
5. Des donnÃ©es peuvent Ãªtre traitÃ©es et utilisÃ©es par les [[Data Scientist]]
    1. Les diffÃ©rentes sous partie de **Employees** peuvent Ãªtre elles-mÃªmes Ãªtre split par pays.
    2. **Tracks** peut maintenant Ãªtre stockÃ© dans une nouvelle database avec des **Tracks** clean et Ãªtre utilisÃ©s par les [[Data Scientist]] et Ãªtre utilisÃ©s pour un moteur de recherche en analysants la similaritÃ©s des musiques par exemple.

En bref, les [[Data Pipeline]] garantissent que les donnÃ©es circulent efficacement au sein de l'organisation

|Automate|Reduce|
|---|---|
|Extraction|Lâ€™intervention humaine|
|Transformation|Les erreurs|
|Combinaison|Temps de circulation des donnÃ©es|
|Validation||
|Chargement des donnÃ©es||

# Comparaison entre ETL et Data Pipelines
Un des termes quâ€™on entend souvent est **ETL**. Il sâ€™agist dâ€™un framework populaire pour la conception de [[Data Pipeline]]. Il divise le flux de donnÃ©es en trois Ã©tapes sÃ©quentielles.

|ETL|Data pipelines|
|---|---|
|Framework populaire pour la conception de pipelines de donnÃ©es|DÃ©placent les donnÃ©es dâ€™un systÃ¨me Ã  un autre|
|**E** pour lâ€™extraction des donnÃ©es|Peuvent suivre lâ€™ETL, mais pas toujours|
|**T** pour la transformation des donnÃ©es extraites|Les donnÃ©es peuvent ne pas Ãªtre transformÃ©es|
|**L** pour le chargement des donnÃ©es transformÃ©es dans une nouvelle base de donnÃ©es|Les donnÃ©es peuvent Ãªtre acheminÃ©es directement vers des applications telles que des outils de visualisation ou Salesforce|
